# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3005
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3008
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3006
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 2998
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3002
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3003
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3005
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3007
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 1: Convert SpatialPolygonsDataFrame to sf object
model_data_sf <- st_as_sf(model_data_sp)
# Step 2: Select a polygon (e.g., the first one)
# for centre figure use polygon number 550
selected_polygon_index <- 3015
selected_polygon <- model_data_sf[selected_polygon_index, ]
# Step 3: Extract centroids of the polygons
centroids <- st_centroid(model_data_sf)
# Step 4: Calculate distances between the centroids (use st_distance for sf objects)
dist_matrix <- st_distance(centroids)
# Step 5: Find the 72 nearest polygons (excluding the selected polygon itself)
nearest_indices <- order(dist_matrix[selected_polygon_index, ])[2:73]
# Create a new column to label the nearest polygons
model_data_sf$category <- "outer"  # Default to outer areas
model_data_sf$category[selected_polygon_index] <- "centre"  # Mark the central polygon
model_data_sf$category[nearest_indices] <- "nearest"  # Mark the nearest polygons
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Step 7: Create the map using tmap
#tm_shape(model_data_sf) + tm_fill("nearest", palette=c("white", "red"), alpha=0.8) + tm_layout(frame=FALSE,legend.show=FALSE)+ tm_borders("black", lwd=0.3)
tm_shape(model_data_sf) +
tm_fill("category", palette = c("centre"="black", "nearest"="orange", "outer"="white"), alpha = 0.8) + tm_layout(frame = FALSE, legend.show = FALSE) + tm_borders("black", lwd = 0.3)
# Clean data sheets and join
lsoa_data1 <- lsoa_data1 %>% slice(-1) %>%  rename(lsoa_code = ...1,
lsoa_name = ...2,
BAME_2011_perc = `BAME (%)`)
pacman::p_load(tidyverse, dplyr, readr, readxl, readODS, here)
# Import data
lsoa_data1 <- read_excel("~/Downloads/lsoa-data.xls", sheet = "iadatasheet1",
skip = 1) %>% dplyr::select(c(1,2),`BAME (%)`)
lsoa_data2 <- read_excel("~/Downloads/lsoa-data.xls", sheet = "iadatasheet2",
skip = 1) %>% dplyr::select(c(1,2),`% No qualifications`,
`No cars or vans in household (%)`,
`Median Annual Household Income estimate (£)`)
# Clean data sheets and join
lsoa_data1 <- lsoa_data1 %>% slice(-1) %>%  rename(lsoa_code = ...1,
lsoa_name = ...2,
BAME_2011_perc = `BAME (%)`)
lsoa_data2 <- lsoa_data2 %>% slice(-1) %>%  rename(lsoa_code = ...1,
lsoa_name = ...2,
no_qualifications_perc = `% No qualifications`,
no_cars_perc = `No cars or vans in household (%)`,
household_median_income = `Median Annual Household Income estimate (£)`) %>%
mutate(carownership_perc = 100-no_cars_perc) %>%
dplyr::select(-no_cars_perc)
lsoa_data <- lsoa_data1 %>%
inner_join(lsoa_data2, by = c("lsoa_code","lsoa_name"))
# Read in journey time dataset from DfT, along with Local Authority names & codes
journeytime_lsoa <- read_ods("~/Downloads/jts0507.ods", sheet = "2019", skip = 6) %>%
dplyr::select(LSOA_code, LA_Code, LA_Name, FoodPTt, FoodCart, FoodWalkt)
journeytime_lsoa <- journeytime_lsoa %>% rename(lsoa_code = LSOA_code,
la_code = LA_Code,
la_name = LA_Name,
food_pt = FoodPTt,
food_car = FoodCart,
food_walk = FoodWalkt)
# Read in Tesco dataset
year_lsoa_grocery <- read_csv("~/Library/CloudStorage/Box-Box/Data/tesco_model/year_lsoa_grocery.csv") %>%
dplyr::select(area_id, avg_age, f_dairy, f_eggs, f_fats_oils, f_sweets, f_grains, f_sauces, f_fruit_veg,
f_fish, f_meat_red, f_poultry, f_readymade, f_soft_drinks) %>%
rename(lsoa_code=area_id, dairy=f_dairy, eggs=f_eggs, `fats & oils`=f_fats_oils,
sweets=f_sweets, grains=f_grains, sauces=f_sauces, `fruit & veg`=f_fruit_veg,
fish=f_fish, `red meat`=f_meat_red, poultry=f_poultry, `ready-made`=f_readymade,
`soft drinks`=f_soft_drinks)
# Merge all three datasets:
cleaned_data <- lsoa_data %>%
inner_join(journeytime_lsoa, by = "lsoa_code") %>%
inner_join(year_lsoa_grocery, by = "lsoa_code")
cleaned_data
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, tidymodels, dplyr, readr, sf, spdep, tmap, readxl, here, GWmodel)
# read in the tibble (cleaned_data) which was prepared in lsoa-data-cleaning-script.R
#cleaned_data <- read_csv()
cleaned_data
# read in shapefile
map_lsoa <- st_read("data/shapefiles/LSOA_boundaries_2011_london.shp") %>%
rename(lsoa_code = LSOA11CD, lsoa_name=LSOA11NM, la_code=LAD11CD, la_name=LAD11NM)
# Join the two dataframes together
london_polygon <- inner_join(map_lsoa, cleaned_data)
cleaned_data_reduced <- cleaned_data %>%
filter(la_name %in% c("Newham", "Tower Hamlets", "Hackney", "Islington", "Lewisham",
"Southwark", "Lambeth", "Wandsworth", "Camden", "Haringey",
"City of London", "Westminster", "Kensington and Chelsea",
"Hammersmith and Fulham", "Enfield", "Redbridge", "Waltham Forest",
"Barnet", "Brent", "Harrow", "Greenwich", "Ealing", "Barking and Dagenham"))
# Plot study area
set.seed(142)
# Define recipe: centre and scale
foodcategory_recipe <- cleaned_data_reduced %>%
dplyr::select(lsoa_code,dairy:`soft drinks`) %>%
recipe(~ .) %>%
step_center(all_numeric()) %>%
step_scale(all_numeric()) %>%
step_pca(all_numeric(), threshold = 0.80, id = "pca") %>%
prep()
# Calculate PCA loadings
loadings <- foodcategory_recipe %>%
tidy(n = 3) %>%  # get tidy output for the first 3 principal components
filter(component %in% c("PC1")) %>%  # filter for the first component
mutate(
value = ifelse(component == "PC1", -value, value),
# flip sign of PC1 loadings
terms_ordered = fct_reorder(terms, abs(value)),
pos = value < 0  # identify whether value is negative (for Figures 2-3)
)
# Percentage variance explained
variance_explained <- foodcategory_recipe %>%
tidy(id = "pca", type = "variance") %>%
dplyr::filter(terms == "percent variance")
# Extract PC scores from foodcategory_recipe
PC_scores <- juice(foodcategory_recipe) %>% mutate(PC1=-PC1)
loadings_plot_horizontal <- loadings %>%
ggplot(aes(x = reorder(terms_ordered, desc(terms_ordered)), y = value, fill = pos)) +
geom_col(show.legend = FALSE) +
scale_y_continuous(breaks = seq(-0.5, 0.4, 0.1)) +
scale_fill_manual(values = c("#fb8072", "#a6cee3")) +
theme_bw() +
theme(
panel.border = element_blank(),
panel.grid.major = element_line(size = 0.5),
panel.grid.minor = element_blank(),
axis.text = element_text(size = 12),
axis.title = element_text(size = 16),
plot.title = element_text(size = 16),
axis.text.x = element_text(angle = 70, vjust = 1, hjust = 1)
) + xlab("") + ylab("")
loadings_plot_horizontal
# Supplementary figure 1:
# Variance explained barplot
varplot <- variance_explained %>%
ggplot(aes(x = component, y = value)) +
geom_col(fill = "#bebebe") + ggtitle("Variance explained") +
xlim(c(0, 5)) + xlab("Principal component")+
ylab("Percent of total variance")+
theme_minimal() + theme(panel.border = element_blank(),
panel.grid.minor = element_blank(), plot.title=element_text(size=16))
varplot
london_polygon <- left_join(london_polygon, PC_scores)
# Figure 3: PC1 map
# define upper and lower bounds (for formatting purposes)
pc_lower <- min(na.omit(london_polygon)$PC1)
pc_upper <- max(na.omit(london_polygon)$PC1)
map_pc1 <- tm_shape(na.omit(london_polygon)) +
tm_polygons("PC1",
fill.scale = tm_scale_continuous(values = "-RdBu", limits = c(pc_lower, pc_upper)),
col_alpha = 0,
tm_legend(title = "", frame = FALSE, limits = c(pc_lower, pc_upper))) +
tm_borders(lwd = 0) +
tm_layout(
frame = FALSE,
legend.reverse = TRUE,
legend.is.portrait = TRUE,
legend.text.size = 0.8,
legend.height = 20
) +
tm_title("")
# plot income
# convert income unit to thousands
london_polygon <- london_polygon %>%
mutate(household_median_income_thousands = household_median_income/1000)
map_income <- tm_shape(na.omit(london_polygon)) + tm_polygons("household_median_income_thousands", tm_scale_continuous(values="Purples"), col_alpha = 0, tm_legend(title="", frame=FALSE)) + tm_layout(frame=FALSE, legend.text.size=1, legend.reverse = TRUE)
# plot BAME
map_BAME <- tm_shape(na.omit(london_polygon)) + tm_polygons("BAME_2011_perc", tm_scale_continuous(values="Purples"), col_alpha = 0, tm_legend(title="", frame=FALSE)) + tm_layout(frame=FALSE, legend.text.size=1.2, legend.reverse=TRUE)
# plot walk-time
map_foodwalk <- tm_shape(na.omit(london_polygon)) + tm_polygons("food_walk", tm_scale_continuous(values="Purples"), col_alpha = 0, tm_legend(title="", frame=FALSE)) + tm_layout(frame=FALSE, legend.text.size=1.2, legend.reverse=TRUE)
# plot car ownership
map_carownership <- tm_shape(na.omit(london_polygon)) + tm_polygons("carownership_perc", tm_scale_continuous(values="Purples"), col_alpha = 0, tm_legend(title="", frame=FALSE)) + tm_layout(frame=FALSE, legend.text.size=1.2, legend.reverse=TRUE)
# plot age
map_age <- tm_shape(na.omit(london_polygon)) + tm_polygons("avg_age", tm_scale_continuous(values="Purples"), col_alpha = 0, tm_legend(title="", frame=FALSE)) + tm_layout(frame=FALSE, legend.text.size=1.2, legend.reverse = TRUE)
# Create spatial weights matrix using queen contiguity scheme
clustering_data <- na.omit(london_polygon)
# Contiguity style weights matrix according to queen criterion
weights <- poly2nb(clustering_data, queen = TRUE, snap = 1e-5) #boundaries <snap distance apart are contiguous
# row standardised spatial weights
weights <- nb2listw(weights, style = "W")
# Global Moran's I for PC1
gmi <- moran.test(clustering_data$PC1, listw = weights)
# LISA cluster instead?
# Compute Local Moran's I
# In addition, we output an attribute data frame "quadr" with mean and median quadrant columns, and a column splitting on the demeaned variable and lagged demeaned variable at zero.
lisa <- localmoran(clustering_data$PC1, weights)
summary(lisa)
# LISA clusters according to significance level of 0.05
significance <- 0.05
clustering_data$clusters <- attributes(lisa)$quadr$mean
clustering_data$clusters[lisa[ ,5] > significance] <- "Insignificant"
clustering_data <- clustering_data %>%
mutate(clusters = case_when(
is.na(clusters) ~ "Insignificant",
TRUE ~ as.factor(clusters)))
clustering_data$clusters <- factor(clustering_data$clusters, levels=c("Low-Low","Low-High","High-Low","High-High","Insignificant"))
# LH and HL are coded as "Insignificant" here - we aren't interested in these
clustering_data <- clustering_data %>%
mutate(clusters_HH_LL = case_when(
clusters == "Low-Low" ~ "Low-Low",
clusters == "High-High" ~ "High-High",
TRUE ~ NA_character_
))
# na.show=FALSE prevents insignificant entries (which we coded as NA) from being plotted!
LISA_map <- tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("red", "blue")), col_alpha=0, tm_legend(title="Clusters", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
LISA_map
# data for our model (remove geometry attribute)
model_data <- clustering_data %>% dplyr::select(PC1, avg_age, carownership_perc, household_median_income, food_walk, BAME_2011_perc, lsoa_code)
my_recipe <- recipe(PC1~., data = model_data %>% dplyr::select(-geometry)) %>%
update_role(lsoa_code, new_role = "ID variable") %>%
update_role(geometry, new_role = "ID variable") %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors()) %>%
step_YeoJohnson(PC1)
# Extract the corresponding lambda value for yeo-johnson transform
lambda_yj <- prep(my_recipe)$steps[[3]]$lambdas
cat("The optimal lambda value for Yeo-Johnson is", lambda_yj, "\n")
# Prep applies the transforms to the data; juice extracts the preprocessed data; convert back to sf object
model_data_transformed <- prep(my_recipe) %>%
juice()
# PC1 has been transformed within "model_data_transformed"
linear_model <- lm(PC1~., data=model_data_transformed %>% select(-geometry,-lsoa_code))
# data for our model (remove geometry attribute)
model_data <- clustering_data %>% dplyr::select(PC1, avg_age, carownership_perc, household_median_income, food_walk, BAME_2011_perc, lsoa_code)
my_recipe <- recipe(PC1~., data = model_data %>% dplyr::select(-geometry)) %>%
update_role(lsoa_code, new_role = "ID variable") %>%
update_role(geometry, new_role = "ID variable") %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors()) %>%
step_YeoJohnson(PC1)
# Extract the corresponding lambda value for yeo-johnson transform
lambda_yj <- prep(my_recipe)$steps[[3]]$lambdas
cat("The optimal lambda value for Yeo-Johnson is", lambda_yj, "\n")
# Prep applies the transforms to the data; juice extracts the preprocessed data; convert back to sf object
model_data_transformed <- prep(my_recipe) %>%
juice()
# PC1 has been transformed within "model_data_transformed"
linear_model <- lm(PC1~., data=model_data_transformed %>% dplyr::select(-geometry,-lsoa_code))
# Check collinearity with variance inflation factors (VIFs)
car::vif(lm_model)
linear_model
linear_model$summary
summary(linear_model)
# extract the residuals from the lm object and put it into our clustering data tibble
clustering_data$linear_model_residuals <- residuals(linear_model)
# Compute Global Moran's I for linear model residuals; same weights as defined earlier
gmi_residuals <- moran.test(clustering_data$linear_model_residuals, weights)
# Compute Local Moran's I for linear model residuals
lisa_residuals <- localmoran(clustering_data$linear_model_residuals, weights)
summary(lisa_residuals)
# significance as defined above;
clustering_data$clusters_residuals <- attributes(lisa_residuals)$quadr$mean
clustering_data$clusters_residuals[lisa[ ,5] > significance] <- "Insignificant"
# clustering of linear model residuals
tm_shape(clustering_data) + tm_polygons("clusters_residuals", fill.scale = tm_scale_categorical(values = c("blue", "lightblue", "coral", "red","grey")), col_alpha=0, tm_legend(title="Clusters", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("red", "blue")), col_alpha=0, tm_legend(title="Clusters", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("red", "blue")), col_alpha=0, tm_legend(title="Clusters", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("red", "blue")), col_alpha=0, tm_legend(title="Clusters", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
# Create spatial weights matrix using queen contiguity scheme
# Making another dataset called "clustering data" for the next section
clustering_data <- london_data
clustering_data <- na.omit(clustering_data)
# Playing around with distance-based measures
# Extracting coordinates and converting to lon-lat form (so that distances are in KM)
#coords <- coordinates(spTransform(as_Spatial(clustering_data$geometry), CRS("+proj=longlat +datum=WGS84")))
# First we want to figure out an upper limit for the distance radius
#coords <- coordinates(as_Spatial(clustering_data))[ ,1:2] #extract XY coordinate points. We must have as_Spatial frame
#k1 <- knn2nb(knearneigh(coords))
#k1dists <- unlist(nbdists(k1, coords, longlat = TRUE)) #Spatial link distance measures
#For longlat=TRUE, great circle distance used
#summary(k1dists)
#Now computing the fixed-distance weights matrix
#weighted_matrix_d <- dnearneigh(coords, 0 , max(k1dists), longlat = TRUE)
#str(weighted_matrix_d)
# Extract the spatial weights for the distance-based weightings matrix
#weights2 <- nb2listw(weighted_matrix_d)
# Contiguity style weights matrix according to queen criterion
# LSOAs are neighbours if they share a common POINT
weights <- poly2nb(clustering_data, queen = TRUE, snap = 1e-5) #boundaries <snap distance apart are contiguous
weights <- nb2listw(weights, style = "W")
# Global Moran's I
gmi <- moran.test(clustering_data$PC1, listw = weights)
# LISA cluster instead?
# Compute Local Moran's I
# In addition, we output an attribute data frame "quadr" with mean and median quadrant columns, and a column splitting on the demeaned variable and lagged demeaned variable at zero.
lisa <- localmoran(clustering_data$PC1, weights)
summary(lisa)
# LISA clusters according to significance (p>0.05 implies not significant)
significance <- 0.05
clustering_data$clusters <- attributes(lisa)$quadr$mean
clustering_data$clusters[lisa[ ,5] > significance] <- "Insignificant"
#clustering_data$clusters
clustering_data <- clustering_data %>%
mutate(clusters = case_when(
is.na(clusters) ~ "Insignificant",
TRUE ~ as.factor(clusters)))
clustering_data$clusters <- factor(clustering_data$clusters, levels=c("Low-Low","Low-High","High-Low","High-High","Insignificant"))
#Map of LISA clusters
lisa_map <- tm_shape(clustering_data) + tm_polygons("clusters", fill.scale = tm_scale_categorical(values = c("blue", "lightblue", "coral", "red","grey")), col_alpha=0, tm_legend(title="Clusters", frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
lisa_map
#----
# Map of LISA clusters without HL and LH
#Map of LISA clusters
# first make a new variable clusters_HH_LL which only keeps the HH and LL
# LH and HL are coded as "Insignificant" here
clustering_data <- clustering_data %>%
mutate(clusters_HH_LL = case_when(
clusters == "Low-Low" ~ "Cold Spot",
clusters == "High-High" ~ "Hot Spot",
TRUE ~ NA_character_
))
# Set the factor levels to the desired order
# clustering_data$clusters_HH_LL <- factor(clustering_data$clusters_HH_LL, levels = c("High-High", "Low-Low", "Insignificant"))
# Add fill_alpha to tm_polygons for view mode
# na.show=FALSE prevents the Missing entries from being plotted!
tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("red", "blue")), col_alpha=0, tm_legend(title="", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
# na.show=FALSE prevents the Missing entries from being plotted!
tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("red", "blue")), col_alpha=0, tm_legend(title="", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
tm_shape(clustering_data) + tm_polygons("clusters_HH_LL", fill.scale = tm_scale_categorical(values = c("blue", "red")), col_alpha=0, tm_legend(title="", na.show = FALSE, frame=FALSE, title.size=1.2, text.size=1)) + tm_borders(lwd=0.1) +  tm_layout(frame=FALSE) + tm_title(text = "")
?here
here
here()
here::here()
setwd(here::here())
here()
read_excel(here("data/lsoa-data.xls"), sheet = "iadatasheet1",
skip = 1) %>% dplyr::select(c(1,2),`BAME (%)`)
