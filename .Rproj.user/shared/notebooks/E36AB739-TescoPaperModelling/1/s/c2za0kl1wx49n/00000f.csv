"0","# Define PCA recipe (and remove representativeness parameter)"
"0","# Centering and scaling all variables before PCA"
"0","fcategory_recipe <- f_category %>% dplyr::select(-c(representativeness_norm)) %>% recipe(~ .) %>% "
"0","  step_center(all_numeric()) %>% step_scale(all_numeric()) %>%"
"0","  step_pca(all_numeric(), threshold = 0.80, id = ""pca"") %>%"
"0","  prep() "
"0",""
"0","# Calculate the PCA loadings"
"0","# Note the sum of these squared loadings sums to 1"
"0","loadings <- fcategory_recipe %>%"
"0","  tidy(n = 3) %>%"
"0","  filter(component %in% c(""PC1"")) %>% # For extra components, add others to this vector"
"0","  mutate(terms_ordered = fct_reorder(terms,abs(value))) %>%"
"0","  mutate(pos=value<0) #This last line is for plotting later (keeps track of highest loadings)"
"0",""
"0","# Percentage of variance explained"
"0","variance_explained <- fcategory_recipe %>% "
"0","  tidy(id = ""pca"", type = ""variance"") %>% "
"0","  dplyr::filter(terms == ""percent variance"")"
"0",""
"0","# Extract the PC scores for each LSOA from fcategory_recipe (juice it)"
"0","PC_scores <- juice(fcategory_recipe) "
"0",""
"0","# Merge PC scores with the rest of the london data (again joining by lsoa names and codes)"
"0","london_data <- left_join(london_poly, PC_scores)"
"1","[38;5;232mJoining with `by = join_by(lsoa_code)`[39m
"
"0","# Currently, education(%) and car ownership(%) are % without, but subtract from 100 so the estimates are % with qualifications and % with cars"
"0","london_data <- london_data %>%"
"0","  mutate("
"0","    qualifications_2011_perc = 100 - no_qualifications_2011_perc,"
"0","    households_with_cars = 100 - households_no_cars"
"0","  )"
